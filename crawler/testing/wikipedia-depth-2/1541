http://old-www.cs.dartmouth.edu/~cs50/data/tse/wikipedia/Pattern_recognition.html
2
<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">

<!-- Mirrored from en.wikipedia.org/wiki/Pattern_recognition by HTTrack Website Copier/3.x [XR&CO'2013], Sat, 29 Mar 2014 23:55:29 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<meta charset="UTF-8" />
<title>Pattern recognition - Wikipedia, the free encyclopedia</title>
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />
<meta name="generator" content="MediaWiki 1.23wmf18" />
<link rel="alternate" href="http://en.wikipedia.org/wiki/android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Pattern_recognition" />
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit" />
<link rel="edit" title="Edit this page" href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit" />
<link rel="apple-touch-icon" href="http://bits.wikimedia.org/apple-touch/wikipedia.png" />
<link rel="shortcut icon" href="http://bits.wikimedia.org/favicon/wikipedia.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="http://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (en)" />
<link rel="EditURI" type="application/rsd+xml" href="http://en.wikipedia.org/w/api.php?action=rsd" />
<link rel="copyright" href="http://creativecommons.org/licenses/by-sa/3.0/" />
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="http://en.wikipedia.org/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
<link rel="canonical" href="Pattern_recognition.html" />
<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.DRN-wizard%2CReferenceTooltips%2Ccharinsert%2Cteahouse%7Cext.rtlcite%2Cwikihiero%7Cext.uls.nojs%7Cext.visualEditor.viewPageTarget.noscript%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.ui.button%7Cskins.common.interface%7Cskins.vector.styles&amp;only=styles&amp;skin=vector&amp;*" />
<meta name="ResourceLoaderDynamicStyles" content="" />
<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=styles&amp;skin=vector&amp;*" />
<style>a:lang(ar),a:lang(kk-arab),a:lang(mzn),a:lang(ps),a:lang(ur){text-decoration:none}
/* cache key: enwiki:resourceloader:filter:minify-css:7:3904d24a08aa08f6a68dc338f9be277e */</style>

<script src="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector&amp;*"></script>
<script>if(window.mw){
mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Pattern_recognition","wgTitle":"Pattern recognition","wgCurRevisionId":600603195,"wgRevisionId":600603195,"wgArticleId":126706,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Pages containing cite templates with deprecated parameters","All articles with unsourced statements","Articles with unsourced statements from January 2011","Machine learning","Formal sciences"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Pattern_recognition","wgIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgWikiEditorEnabledModules":{"toolbar":true,"dialogs":true,"hidesig":true,"templateEditor":false,"templates":false,"preview":false,"previewDialog":false,"publish":false,"toc":false},"wgBetaFeaturesFeatures":[],"wgVisualEditor":{"isPageWatched":false,"magnifyClipIconURL":"//bits.wikimedia.org/static-1.23wmf18/skins/common/images/magnify-clip.png","pageLanguageCode":"en","pageLanguageDir":"ltr","svgMaxSize":2048},"wikilove-recipient":"","wikilove-anon":0,"wgGuidedTourHelpGuiderUrl":"Help:Guided tours/guider","wgFlowTermsOfUseEdit":"By saving changes, you agree to our \u003Ca class=\"external text\" href=\"//wikimediafoundation.org/wiki/Terms_of_use\"\u003ETerms of Use\u003C/a\u003E and agree to irrevocably release your text under the \u003Ca rel=\"nofollow\" class=\"external text\" href=\"//creativecommons.org/licenses/by-sa/3.0\"\u003ECC BY-SA 3.0 License\u003C/a\u003E and \u003Ca class=\"external text\" href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License\"\u003EGFDL\u003C/a\u003E","wgULSAcceptLanguageList":["en-us","en"],"wgULSCurrentAutonym":"English","wgFlaggedRevsParams":{"tags":{"status":{"levels":1,"quality":2,"pristine":3}}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q378859"});
}</script><script>if(window.mw){
mw.loader.implement("user.options",function(){mw.user.options.set({"ccmeonemails":0,"cols":80,"date":"default","diffonly":0,"disablemail":0,"editfont":"default","editondblclick":0,"editsectiononrightclick":0,"enotifminoredits":0,"enotifrevealaddr":0,"enotifusertalkpages":1,"enotifwatchlistpages":0,"extendwatchlist":0,"fancysig":0,"forceeditsummary":0,"gender":"unknown","hideminor":0,"hidepatrolled":0,"imagesize":2,"math":0,"minordefault":0,"newpageshidepatrolled":0,"nickname":"","norollbackdiff":0,"numberheadings":0,"previewonfirst":0,"previewontop":1,"rcdays":7,"rclimit":50,"rememberpassword":0,"rows":25,"showhiddencats":false,"shownumberswatching":1,"showtoolbar":1,"skin":"vector","stubthreshold":0,"thumbsize":4,"underline":2,"uselivepreview":0,"usenewrc":0,"watchcreations":1,"watchdefault":0,"watchdeletion":0,"watchlistdays":3,"watchlisthideanons":0,"watchlisthidebots":0,"watchlisthideliu":0,"watchlisthideminor":0,"watchlisthideown":0,"watchlisthidepatrolled":0,"watchmoves":0,
"wllimit":250,"useeditwarning":1,"prefershttps":1,"flaggedrevssimpleui":1,"flaggedrevsstable":0,"flaggedrevseditdiffs":true,"flaggedrevsviewdiffs":false,"usebetatoolbar":1,"usebetatoolbar-cgd":1,"visualeditor-enable":0,"visualeditor-enable-experimental":0,"visualeditor-enable-mwmath":0,"visualeditor-betatempdisable":0,"wikilove-enabled":1,"echo-subscriptions-web-page-review":true,"echo-subscriptions-email-page-review":false,"ep_showtoplink":false,"ep_bulkdelorgs":false,"ep_bulkdelcourses":true,"ep_showdyk":true,"echo-subscriptions-web-education-program":true,"echo-subscriptions-email-education-program":false,"echo-notify-show-link":true,"echo-show-alert":true,"echo-email-frequency":0,"echo-email-format":"html","echo-subscriptions-email-system":true,"echo-subscriptions-web-system":true,"echo-subscriptions-email-other":false,"echo-subscriptions-web-other":true,"echo-subscriptions-email-edit-user-talk":false,"echo-subscriptions-web-edit-user-talk":true,"echo-subscriptions-email-reverted":
false,"echo-subscriptions-web-reverted":true,"echo-subscriptions-email-article-linked":false,"echo-subscriptions-web-article-linked":false,"echo-subscriptions-email-mention":false,"echo-subscriptions-web-mention":true,"echo-subscriptions-web-edit-thank":true,"echo-subscriptions-email-edit-thank":false,"echo-subscriptions-web-flow-discussion":true,"echo-subscriptions-email-flow-discussion":false,"gettingstarted-task-toolbar-show-intro":true,"uls-preferences":"","language":"en","variant-gan":"gan","variant-iu":"iu","variant-kk":"kk","variant-ku":"ku","variant-shi":"shi","variant-sr":"sr","variant-tg":"tg","variant-uz":"uz","variant-zh":"zh","searchNs0":true,"searchNs1":false,"searchNs2":false,"searchNs3":false,"searchNs4":false,"searchNs5":false,"searchNs6":false,"searchNs7":false,"searchNs8":false,"searchNs9":false,"searchNs10":false,"searchNs11":false,"searchNs12":false,"searchNs13":false,"searchNs14":false,"searchNs15":false,"searchNs100":false,"searchNs101":false,"searchNs108":false,
"searchNs109":false,"searchNs118":false,"searchNs119":false,"searchNs446":false,"searchNs447":false,"searchNs710":false,"searchNs711":false,"searchNs828":false,"searchNs829":false,"gadget-teahouse":1,"gadget-ReferenceTooltips":1,"gadget-DRN-wizard":1,"gadget-charinsert":1,"gadget-mySandbox":1,"variant":"en"});},{},{});mw.loader.implement("user.tokens",function(){mw.user.tokens.set({"editToken":"+\\","patrolToken":false,"watchToken":false});},{},{});
/* cache key: enwiki:resourceloader:filter:minify-js:7:0378eace27e3aee431624f77f4809281 */
}</script>
<script>if(window.mw){
mw.loader.load(["mediawiki.page.startup","mediawiki.legacy.wikibits","mediawiki.legacy.ajax","ext.centralauth.centralautologin","ext.visualEditor.viewPageTarget.init","ext.uls.init","ext.uls.interface","wikibase.client.init","ext.centralNotice.bannerController","skins.vector.js"]);
}</script>
<link rel="dns-prefetch" href="http://meta.wikimedia.org/" /><!--[if lt IE 7]><style type="text/css">body{behavior:url("/w/static-1.23wmf18/skins/vector/csshover.min.htc")}</style><![endif]--></head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Pattern_recognition skin-vector action-view vector-animateLayout">
		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="mw-js-message" style="display:none;"></div>
						<div id="siteNotice"><!-- CentralNotice --></div>
						<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Pattern recognition</span></h1>
			<div id="bodyContent">
								<div id="siteSub">From Wikipedia, the free encyclopedia</div>
								<div id="contentSub"></div>
												<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="#mw-navigation">navigation</a>, 					<a href="#p-search">search</a>
				</div>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="dablink">For other uses, see <a href="http://en.wikipedia.org/wiki/Pattern_recognition_(disambiguation)" title="Pattern recognition (disambiguation)">Pattern recognition (disambiguation)</a>.</div>
<p>In <a href="Machine_learning.html" title="Machine learning">machine learning</a>, <b>pattern recognition</b> is the assignment of a label to a given input value. In statistics, <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">discriminant analysis</a> was introduced for this same purpose in 1936. An example of pattern recognition is <a href="http://en.wikipedia.org/wiki/Classification_(machine_learning)" title="Classification (machine learning)" class="mw-redirect">classification</a>, which attempts to assign each input value to one of a given set of <i>classes</i> (for example, determine whether a given email is "spam" or "non-spam"). However, pattern recognition is a more general problem that encompasses other types of output as well. Other examples are <a href="http://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression</a>, which assigns a real-valued output to each input; <a href="http://en.wikipedia.org/wiki/Sequence_labeling" title="Sequence labeling">sequence labeling</a>, which assigns a class to each member of a sequence of values (for example, <a href="http://en.wikipedia.org/wiki/Part_of_speech_tagging" title="Part of speech tagging" class="mw-redirect">part of speech tagging</a>, which assigns a <a href="http://en.wikipedia.org/wiki/Part_of_speech" title="Part of speech">part of speech</a> to each word in an input sentence); and <a href="Parsing.html" title="Parsing">parsing</a>, which assigns a <a href="http://en.wikipedia.org/wiki/Parse_tree" title="Parse tree">parse tree</a> to an input sentence, describing the <a href="http://en.wikipedia.org/wiki/Syntactic_structure" title="Syntactic structure" class="mw-redirect">syntactic structure</a> of the sentence.</p>
<p>Pattern recognition algorithms generally aim to provide a reasonable answer for all possible inputs and to perform "most likely" matching of the inputs, taking into account their statistical variation. This is opposed to <i><a href="http://en.wikipedia.org/wiki/Pattern_matching" title="Pattern matching">pattern matching</a></i> algorithms, which look for exact matches in the input with pre-existing patterns. A common example of a pattern-matching algorithm is <a href="http://en.wikipedia.org/wiki/Regular_expression" title="Regular expression">regular expression</a> matching, which looks for patterns of a given sort in textual data and is included in the search capabilities of many <a href="Text_editor.html" title="Text editor">text editors</a> and <a href="http://en.wikipedia.org/wiki/Word_processor" title="Word processor">word processors</a>. In contrast to pattern recognition, pattern matching is generally not considered a type of machine learning, although pattern-matching algorithms (especially with fairly general, carefully tailored patterns) can sometimes succeed in providing similar-quality output to the sort provided by pattern-recognition algorithms.</p>
<p>Pattern recognition is studied in many fields, including <a href="http://en.wikipedia.org/wiki/Psychology" title="Psychology">psychology</a>, <a href="http://en.wikipedia.org/wiki/Psychiatry" title="Psychiatry">psychiatry</a>, <a href="http://en.wikipedia.org/wiki/Ethology" title="Ethology">ethology</a>, <a href="http://en.wikipedia.org/wiki/Cognitive_science" title="Cognitive science">cognitive science</a>, <a href="http://en.wikipedia.org/wiki/Three-phase_traffic_theory" title="Three-phase traffic theory">traffic flow</a> and <a href="Computer_science.html" title="Computer science">computer science</a>.</p>
<p></p>
<div id="toc" class="toc">
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Probabilistic_classifiers"><span class="tocnumber">1.1</span> <span class="toctext">Probabilistic classifiers</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#How_many_feature_variables_are_important.3F"><span class="tocnumber">1.2</span> <span class="toctext">How many feature variables are important?</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#Problem_statement_.28supervised_version.29"><span class="tocnumber">2</span> <span class="toctext">Problem statement (supervised version)</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Frequentist_or_Bayesian_approach_to_pattern_recognition.3F"><span class="tocnumber">2.1</span> <span class="toctext">Frequentist or Bayesian approach to pattern recognition?</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#Uses"><span class="tocnumber">3</span> <span class="toctext">Uses</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Algorithms"><span class="tocnumber">4</span> <span class="toctext">Algorithms</span></a>
<ul>
<li class="toclevel-2 tocsection-8"><a href="#Classification_algorithms_.28supervised_algorithms_predicting_categorical_labels.29"><span class="tocnumber">4.1</span> <span class="toctext">Classification algorithms (supervised algorithms predicting categorical labels)</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Clustering_algorithms_.28unsupervised_algorithms_predicting_categorical_labels.29"><span class="tocnumber">4.2</span> <span class="toctext">Clustering algorithms (unsupervised algorithms predicting categorical labels)</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Ensemble_learning_algorithms_.28supervised_meta-algorithms_for_combining_multiple_learning_algorithms_together.29"><span class="tocnumber">4.3</span> <span class="toctext">Ensemble learning algorithms (supervised meta-algorithms for combining multiple learning algorithms together)</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#General_algorithms_for_predicting_arbitrarily-structured_.28sets_of.29_labels"><span class="tocnumber">4.4</span> <span class="toctext">General algorithms for predicting arbitrarily-structured (sets of) labels</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Multilinear_subspace_learning_algorithms_.28predicting_labels_of_multidimensional_data_using_tensor_representations.29"><span class="tocnumber">4.5</span> <span class="toctext">Multilinear subspace learning algorithms (predicting labels of multidimensional data using tensor representations)</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Parsing_algorithms_.28predicting_tree_structured_labels.29"><span class="tocnumber">4.6</span> <span class="toctext">Parsing algorithms (predicting tree structured labels)</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Real-valued_sequence_labeling_algorithms_.28predicting_sequences_of_real-valued_labels.29"><span class="tocnumber">4.7</span> <span class="toctext">Real-valued sequence labeling algorithms (predicting sequences of real-valued labels)</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#Regression_algorithms_.28predicting_real-valued_labels.29"><span class="tocnumber">4.8</span> <span class="toctext">Regression algorithms (predicting real-valued labels)</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Sequence_labeling_algorithms_.28predicting_sequences_of_categorical_labels.29"><span class="tocnumber">4.9</span> <span class="toctext">Sequence labeling algorithms (predicting sequences of categorical labels)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-17"><a href="#Which_classifier_to_choose_for_a_classification_task.3F"><span class="tocnumber">5</span> <span class="toctext">Which classifier to choose for a classification task?</span></a>
<ul>
<li class="toclevel-2 tocsection-18"><a href="#Supervised_classification"><span class="tocnumber">5.1</span> <span class="toctext">Supervised classification</span></a></li>
<li class="toclevel-2 tocsection-19"><a href="#Unsupervised_classification"><span class="tocnumber">5.2</span> <span class="toctext">Unsupervised classification</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-20"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="#Further_reading"><span class="tocnumber">8</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<p></p>
<h2><span class="mw-headline" id="Overview">Overview</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=1" title="Edit section: Overview">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Pattern recognition is generally categorized according to the type of learning procedure used to generate the output value. <i><a href="http://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a></i> assumes that a set of <i>training data</i> (the <i><a href="http://en.wikipedia.org/wiki/Training_set" title="Training set">training set</a></i>) has been provided, consisting of a set of instances that have been properly labeled by hand with the correct output. A learning procedure then generates a <i>model</i> that attempts to meet two sometimes conflicting objectives: Perform as well as possible on the training data, and generalize as well as possible to new data (usually, this means being as simple as possible, for some technical definition of "simple", in accordance with <a href="http://en.wikipedia.org/wiki/Occam%27s_Razor" title="Occam's Razor" class="mw-redirect">Occam's Razor</a>, discussed below). <a href="http://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a>, on the other hand, assumes training data that has not been hand-labeled, and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances. A combination of the two that has recently been explored is <a href="http://en.wikipedia.org/wiki/Semi-supervised_learning" title="Semi-supervised learning">semi-supervised learning</a>, which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data). Note that in cases of unsupervised learning, there may be no training data at all to speak of; in other words, the data to be labeled <i>is</i> the training data.</p>
<p>Note that sometimes different terms are used to describe the corresponding supervised and unsupervised learning procedures for the same type of output. For example, the unsupervised equivalent of classification is normally known as <i><a href="http://en.wikipedia.org/wiki/Data_clustering" title="Data clustering" class="mw-redirect">clustering</a></i>, based on the common perception of the task as involving no training data to speak of, and of grouping the input data into <i>clusters</i> based on some inherent similarity measure (e.g. the <a href="http://en.wikipedia.org/wiki/Distance" title="Distance">distance</a> between instances, considered as vectors in a multi-dimensional <a href="http://en.wikipedia.org/wiki/Vector_space" title="Vector space">vector space</a>), rather than assigning each input instance into one of a set of pre-defined classes. Note also that in some fields, the terminology is different: For example, in <a href="http://en.wikipedia.org/wiki/Community_ecology" title="Community ecology" class="mw-redirect">community ecology</a>, the term "classification" is used to refer to what is commonly known as "clustering".</p>
<p>The piece of input data for which an output value is generated is formally termed an <i>instance</i>. The instance is formally described by a <a href="http://en.wikipedia.org/wiki/Feature_vector" title="Feature vector">vector</a> of <i>features</i>, which together constitute a description of all known characteristics of the instance. (These feature vectors can be seen as defining points in an appropriate <a href="http://en.wikipedia.org/wiki/Space_(mathematics)" title="Space (mathematics)">multidimensional space</a>, and methods for manipulating vectors in <a href="http://en.wikipedia.org/wiki/Vector_space" title="Vector space">vector spaces</a> can be correspondingly applied to them, such as computing the <a href="http://en.wikipedia.org/wiki/Dot_product" title="Dot product">dot product</a> or the angle between two vectors.) Typically, features are either <a href="http://en.wikipedia.org/wiki/Categorical_data" title="Categorical data" class="mw-redirect">categorical</a> (also known as <a href="http://en.wikipedia.org/wiki/Nominal_data" title="Nominal data" class="mw-redirect">nominal</a>, i.e., consisting of one of a set of unordered items, such as a gender of "male" or "female", or a blood type of "A", "B", "AB" or "O"), <a href="http://en.wikipedia.org/wiki/Ordinal_data" title="Ordinal data">ordinal</a> (consisting of one of a set of ordered items, e.g., "large", "medium" or "small"), <a href="http://en.wikipedia.org/wiki/Integer" title="Integer">integer-valued</a> (e.g., a count of the number of occurrences of a particular word in an email) or <a href="http://en.wikipedia.org/wiki/Real_number" title="Real number">real-valued</a> (e.g., a measurement of blood pressure). Often, categorical and ordinal data are grouped together; likewise for integer-valued and real-valued data. Furthermore, many algorithms work only in terms of categorical data and require that real-valued or integer-valued data be <i>discretized</i> into groups (e.g., less than 5, between 5 and 10, or greater than 10).</p>
<h3><span class="mw-headline" id="Probabilistic_classifiers">Probabilistic classifiers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=2" title="Edit section: Probabilistic classifiers">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Many common pattern recognition algorithms are <i>probabilistic</i> in nature, in that they use <a href="http://en.wikipedia.org/wiki/Statistical_inference" title="Statistical inference">statistical inference</a> to find the best label for a given instance. Unlike other algorithms, which simply output a "best" label, often probabilistic algorithms also output a <a href="http://en.wikipedia.org/wiki/Probability" title="Probability">probability</a> of the instance being described by the given label. In addition, many probabilistic algorithms output a list of the <i>N</i>-best labels with associated probabilities, for some value of <i>N</i>, instead of simply a single best label. When the number of possible labels is fairly small (e.g., in the case of <a href="http://en.wikipedia.org/wiki/Classification_(machine_learning)" title="Classification (machine learning)" class="mw-redirect">classification</a>), <i>N</i> may be set so that the probability of all possible labels is output. Probabilistic algorithms have many advantages over non-probabilistic algorithms:</p>
<ul>
<li>They output a confidence value associated with their choice. (Note that some other algorithms may also output confidence values, but in general, only for probabilistic algorithms is this value mathematically grounded in <a href="http://en.wikipedia.org/wiki/Probability_theory" title="Probability theory">probability theory</a>. Non-probabilistic confidence values can in general not be given any specific meaning, and only used to compare against other confidence values output by the same algorithm.)</li>
<li>Correspondingly, they can <i>abstain</i> when the confidence of choosing any particular output is too low.</li>
<li>Because of the probabilities output, probabilistic pattern-recognition algorithms can be more effectively incorporated into larger machine-learning tasks, in a way that partially or completely avoids the problem of <i>error propagation</i>.</li>
</ul>
<h3><span class="mw-headline" id="How_many_feature_variables_are_important.3F">How many feature variables are important?</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=3" title="Edit section: How many feature variables are important?">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="http://en.wikipedia.org/wiki/Feature_selection" title="Feature selection">Feature selection</a> algorithms, attempt to directly prune out redundant or irrelevant features. A general introduction to <a href="http://en.wikipedia.org/wiki/Feature_selection" title="Feature selection">feature selection</a> which summarizes approaches and challenges, has been given.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup> The complexity of feature-selection is, because of its non-monotonous character, an <a href="http://en.wikipedia.org/wiki/Optimization_problem" title="Optimization problem">optimization problem</a> where given a total of <img class="tex" alt="n" src="http://upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> features the <a href="http://en.wikipedia.org/wiki/Powerset" title="Powerset" class="mw-redirect">powerset</a> consisting of all <img class="tex" alt="2^n-1" src="http://upload.wikimedia.org/math/1/6/5/1653c723c348c6f7f54f6669a5f3c4e7.png" /> subsets of features need to be explored. The <a href="http://en.wikipedia.org/wiki/Branch_and_bound" title="Branch and bound">Branch-and-Bound algorithm</a> <sup id="cite_ref-2" class="reference"><a href="#cite_note-2"><span>[</span>2<span>]</span></a></sup> does reduce this complexity but is intractable for medium to large values of the number of available features <img class="tex" alt="n" src="http://upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" />. For a large-scale comparison of feature-selection algorithms see .<sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup></p>
<p>Techniques to transform the raw feature vectors (<b>feature extraction</b>) are sometimes used prior to application of the pattern-matching algorithm. For example, <a href="http://en.wikipedia.org/wiki/Feature_extraction" title="Feature extraction">feature extraction</a> algorithms attempt to reduce a large-dimensionality feature vector into a smaller-dimensionality vector that is easier to work with and encodes less redundancy, using mathematical techniques such as <a href="http://en.wikipedia.org/wiki/Principal_components_analysis" title="Principal components analysis" class="mw-redirect">principal components analysis</a> (PCA). The distinction between <b>feature selection</b> and <b>feature extraction</b> is that the resulting features after feature extraction has taken place are of a different sort than the original features and may not easily be interpretable, while the features left after feature selection are simply a subset of the original features.</p>
<h2><span class="mw-headline" id="Problem_statement_.28supervised_version.29">Problem statement (supervised version)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=4" title="Edit section: Problem statement (supervised version)">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Formally, the problem of <a href="http://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">supervised</a> pattern recognition can be stated as follows: Given an unknown function <img class="tex" alt="g:\mathcal{X}\rightarrow\mathcal{Y}" src="http://upload.wikimedia.org/math/8/e/2/8e25777fd01426ffdb9d74a52505b2c1.png" /> (the <i>ground truth</i>) that maps input instances <img class="tex" alt="\boldsymbol{x} \in \mathcal{X}" src="http://upload.wikimedia.org/math/9/4/2/94265305f9ee8cd9f46b24aa1973e40a.png" /> to output labels <img class="tex" alt="y \in \mathcal{Y}" src="http://upload.wikimedia.org/math/1/7/d/17db219c3823b764bed6dc6e66705caf.png" />, along with training data <img class="tex" alt="\mathbf{D} = \{(\boldsymbol{x}_1,y_1),\dots,(\boldsymbol{x}_n, y_n)\}" src="http://upload.wikimedia.org/math/d/7/b/d7b87d5b276aa47f87f01d9b7bcab9aa.png" /> assumed to represent accurate examples of the mapping, produce a function <img class="tex" alt="h:\mathcal{X}\rightarrow\mathcal{Y}" src="http://upload.wikimedia.org/math/6/2/5/625a7792bca53a680d1d4d5277d075f4.png" /> that approximates as closely as possible the correct mapping <img class="tex" alt="g" src="http://upload.wikimedia.org/math/b/2/f/b2f5ff47436671b6e533d8dc3614845d.png" />. (For example, if the problem is filtering spam, then <img class="tex" alt="\boldsymbol{x}_i" src="http://upload.wikimedia.org/math/6/e/c/6ecd473b82c65efe68e9fdc8b0db60cd.png" /> is some representation of an email and <img class="tex" alt="y" src="http://upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png" /> is either "spam" or "non-spam"). In order for this to be a well-defined problem, "approximates as closely as possible" needs to be defined rigorously. In <a href="http://en.wikipedia.org/wiki/Decision_theory" title="Decision theory">decision theory</a>, this is defined by specifying a <a href="http://en.wikipedia.org/wiki/Loss_function" title="Loss function">loss function</a> that assigns a specific value to "loss" resulting from producing an incorrect label. The goal then is to minimize the <a href="http://en.wikipedia.org/wiki/Expected_value" title="Expected value">expected</a> loss, with the expectation taken over the <a href="http://en.wikipedia.org/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> of <img class="tex" alt="\mathcal{X}" src="http://upload.wikimedia.org/math/5/4/8/548ad3254513a0a221b4b07fd87e5d9a.png" />. In practice, neither the distribution of <img class="tex" alt="\mathcal{X}" src="http://upload.wikimedia.org/math/5/4/8/548ad3254513a0a221b4b07fd87e5d9a.png" /> nor the ground truth function <img class="tex" alt="g:\mathcal{X}\rightarrow\mathcal{Y}" src="http://upload.wikimedia.org/math/8/e/2/8e25777fd01426ffdb9d74a52505b2c1.png" /> are known exactly, but can be computed only empirically by collecting a large number of samples of <img class="tex" alt="\mathcal{X}" src="http://upload.wikimedia.org/math/5/4/8/548ad3254513a0a221b4b07fd87e5d9a.png" /> and hand-labeling them using the correct value of <img class="tex" alt="\mathcal{Y}" src="http://upload.wikimedia.org/math/0/7/c/07c8b435aba828baf92405c04f581968.png" /> (a time-consuming process, which is typically the limiting factor in the amount of data of this sort that can be collected). The particular loss function depends on the type of label being predicted. For example, in the case of <a href="http://en.wikipedia.org/wiki/Classification_(machine_learning)" title="Classification (machine learning)" class="mw-redirect">classification</a>, the simple <a href="http://en.wikipedia.org/wiki/Zero-one_loss_function" title="Zero-one loss function" class="mw-redirect">zero-one loss function</a> is often sufficient. This corresponds simply to assigning a loss of 1 to any incorrect labeling and implies that the optimal classifier minimizes the <a href="http://en.wikipedia.org/wiki/Bayes_error_rate" title="Bayes error rate">error rate</a> on independent test data (i.e. counting up the fraction of instances that the learned function <img class="tex" alt="h:\mathcal{X}\rightarrow\mathcal{Y}" src="http://upload.wikimedia.org/math/6/2/5/625a7792bca53a680d1d4d5277d075f4.png" /> labels wrongly, which is equivalent to maximizing the number of correctly classified instances). The goal of the learning procedure is then to minimize the error rate (maximize the <a href="http://en.wikipedia.org/wiki/Correctness" title="Correctness">correctness</a>) on a "typical" test set.</p>
<p>For a probabilistic pattern recognizer, the problem is instead to estimate the probability of each possible output label given a particular input instance, i.e., to estimate a function of the form</p>
<dl>
<dd><img class="tex" alt="p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = f\left(\boldsymbol{x};\boldsymbol{\theta}\right)" src="http://upload.wikimedia.org/math/b/f/8/bf8b3266655d88c32941e2064b8b6932.png" /></dd>
</dl>
<p>where the <a href="http://en.wikipedia.org/wiki/Feature_vector" title="Feature vector">feature vector</a> input is <img class="tex" alt="\boldsymbol{x}" src="http://upload.wikimedia.org/math/2/5/6/2563cff13138588d58b12f9d995c3ca0.png" />, and the function <i>f</i> is typically parameterized by some parameters <img class="tex" alt="\boldsymbol{\theta}" src="http://upload.wikimedia.org/math/2/8/9/28964e5d44aaa561601a17e49bb5a8d9.png" />.<sup id="cite_ref-4" class="reference"><a href="#cite_note-4"><span>[</span>4<span>]</span></a></sup> In a <a href="http://en.wikipedia.org/wiki/Discriminative_model" title="Discriminative model">discriminative</a> approach to the problem, <i>f</i> is estimated directly. In a <a href="http://en.wikipedia.org/wiki/Generative_model" title="Generative model">generative</a> approach, however, the inverse probability <img class="tex" alt="p({\boldsymbol{x}|\rm label})" src="http://upload.wikimedia.org/math/6/7/d/67d8c1debc0741c7a7aa791e8993a069.png" /> is instead estimated and combined with the <a href="http://en.wikipedia.org/wiki/Prior_probability" title="Prior probability">prior probability</a> <img class="tex" alt="p({\rm label}|\boldsymbol\theta)" src="http://upload.wikimedia.org/math/4/9/0/4901d5a425e932fc5423974cc0dfaf94.png" /> using <a href="http://en.wikipedia.org/wiki/Bayes%27_rule" title="Bayes' rule">Bayes' rule</a>, as follows:</p>
<dl>
<dd><img class="tex" alt="p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = \frac{p({\boldsymbol{x}|\rm label}) p({\rm label|\boldsymbol\theta})}{\sum_{L \in \text{all labels}} p(\boldsymbol{x}|L) p(L|\boldsymbol\theta)}." src="http://upload.wikimedia.org/math/9/b/c/9bcf73136a71b5f5823290c13287630e.png" /></dd>
</dl>
<p>When the labels are <a href="http://en.wikipedia.org/wiki/Continuous_distribution" title="Continuous distribution" class="mw-redirect">continuously distributed</a> (e.g., in <a href="http://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression analysis</a>), the denominator involves <a href="http://en.wikipedia.org/wiki/Integral" title="Integral">integration</a> rather than summation:</p>
<dl>
<dd><img class="tex" alt="p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = \frac{p({\boldsymbol{x}|\rm label}) p({\rm label|\boldsymbol\theta})}{\int_{L \in \text{all labels}} p(\boldsymbol{x}|L) p(L|\boldsymbol\theta) \operatorname{d}L}." src="http://upload.wikimedia.org/math/2/b/6/2b669481ca39d6b9ecd0162009ae6de9.png" /></dd>
</dl>
<p>The value of <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" /> is typically learned using <a href="http://en.wikipedia.org/wiki/Maximum_a_posteriori" title="Maximum a posteriori" class="mw-redirect">maximum a posteriori</a> (MAP) estimation. This finds the best value that simultaneously meets two conflicting objects: To perform as well as possible on the training data (smallest <a href="http://en.wikipedia.org/wiki/Bayes_error_rate" title="Bayes error rate">error-rate</a>) and to find the simplest possible model. Essentially, this combines <a href="http://en.wikipedia.org/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> estimation with a <a href="http://en.wikipedia.org/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a> procedure that favors simpler models over more complex models. In a <a href="http://en.wikipedia.org/wiki/Bayesian_inference" title="Bayesian inference">Bayesian</a> context, the regularization procedure can be viewed as placing a <a href="http://en.wikipedia.org/wiki/Prior_probability" title="Prior probability">prior probability</a> <img class="tex" alt="p(\boldsymbol\theta)" src="http://upload.wikimedia.org/math/3/5/3/353feed0a1961bfbb2daa124d42c2c9b.png" /> on different values of <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" />. Mathematically:</p>
<dl>
<dd><img class="tex" alt="\boldsymbol\theta^* = \arg \max_{\boldsymbol\theta} p(\boldsymbol\theta|\mathbf{D})" src="http://upload.wikimedia.org/math/c/2/e/c2e233f8cfc391e5e894028b3d07689f.png" /></dd>
</dl>
<p>where <img class="tex" alt="\boldsymbol\theta^*" src="http://upload.wikimedia.org/math/9/5/9/95916743dd8ed5ddfbc6e14810af0d91.png" /> is the value used for <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" /> in the subsequent evaluation procedure, and <img class="tex" alt="p(\boldsymbol\theta|\mathbf{D})" src="http://upload.wikimedia.org/math/e/b/b/ebb3ef58f318ca0ae16a5ea20cf26368.png" />, the <a href="http://en.wikipedia.org/wiki/Posterior_probability" title="Posterior probability">posterior probability</a> of <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" />, is given by</p>
<dl>
<dd><img class="tex" alt="p(\boldsymbol\theta|\mathbf{D}) = \left[\prod_{i=1}^n p(y_i|\boldsymbol{x}_i,\boldsymbol\theta) \right] p(\boldsymbol\theta)." src="http://upload.wikimedia.org/math/2/6/0/260553e2651c4f4865feec3431c8e315.png" /></dd>
</dl>
<p>In the <a href="http://en.wikipedia.org/wiki/Bayesian_statistics" title="Bayesian statistics">Bayesian</a> approach to this problem, instead of choosing a single parameter vector <img class="tex" alt="\boldsymbol{\theta}^*" src="http://upload.wikimedia.org/math/8/c/c/8cc715830196019ed645eeaed5c34497.png" />, the probability of a given label for a new instance <img class="tex" alt="\boldsymbol{x}" src="http://upload.wikimedia.org/math/2/5/6/2563cff13138588d58b12f9d995c3ca0.png" /> is computed by integrating over all possible values of <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" />, weighted according to the posterior probability:</p>
<dl>
<dd><img class="tex" alt="p({\rm label}|\boldsymbol{x}) = \int p({\rm label}|\boldsymbol{x},\boldsymbol\theta)p(\boldsymbol{\theta}|\mathbf{D}) \operatorname{d}\boldsymbol{\theta}." src="http://upload.wikimedia.org/math/6/5/6/656efc7afee0e3e59fc06bb665e8f8c8.png" /></dd>
</dl>
<h3><span class="mw-headline" id="Frequentist_or_Bayesian_approach_to_pattern_recognition.3F">Frequentist or Bayesian approach to pattern recognition?</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=5" title="Edit section: Frequentist or Bayesian approach to pattern recognition?">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The first pattern classifier – the linear discriminant presented by <a href="http://en.wikipedia.org/wiki/Fisher_discriminant_analysis" title="Fisher discriminant analysis" class="mw-redirect">Fisher</a> – was developed in the <a href="http://en.wikipedia.org/wiki/Frequentist_inference" title="Frequentist inference">Frequentist</a> tradition. The frequentist approach entails that the model parameters are considered unknown, but objective. The parameters are then computed (estimated) from the collected data. For the linear discriminant, these parameters are precisely the mean vectors and the <a href="http://en.wikipedia.org/wiki/Covariance_matrix" title="Covariance matrix">Covariance matrix</a>. Also the probability of each class <img class="tex" alt="p({\rm label}|\boldsymbol\theta)" src="http://upload.wikimedia.org/math/4/9/0/4901d5a425e932fc5423974cc0dfaf94.png" /> is estimated from the collected dataset. Note that the usage of ‘<a href="http://en.wikipedia.org/wiki/Bayes_rule" title="Bayes rule" class="mw-redirect">Bayes rule</a>’ in a pattern classifier does not make the classification approach Bayesian.</p>
<p><a href="http://en.wikipedia.org/wiki/Bayesian_inference" title="Bayesian inference">Bayesian statistics</a> has its origin in Greek philosophy where a distinction was already made between the ‘<a href="http://en.wikipedia.org/wiki/A_priori_and_a_posteriori" title="A priori and a posteriori">a priori</a>’ and the ‘<a href="http://en.wikipedia.org/wiki/A_priori_and_a_posteriori" title="A priori and a posteriori">a posteriori</a>’ knowledge. Later <a href="http://en.wikipedia.org/wiki/A_priori_and_a_posteriori#Immanuel_Kant" title="A priori and a posteriori">Kant</a> defined his distinction between what is a priori known – before observation – and the empirical knowledge gained from observations. In a Bayesian pattern classifier, the class probabilities <img class="tex" alt="p({\rm label}|\boldsymbol\theta)" src="http://upload.wikimedia.org/math/4/9/0/4901d5a425e932fc5423974cc0dfaf94.png" /> can be chosen by the user, which are then a priori. Moreover, experience quantified as a priori parameter values can be weighted with empirical observations – using e.g., the <a href="http://en.wikipedia.org/wiki/Beta_distribution" title="Beta distribution">Beta-</a> (<a href="http://en.wikipedia.org/wiki/Conjugate_prior_distribution" title="Conjugate prior distribution" class="mw-redirect">conjugate prior</a>) and <a href="http://en.wikipedia.org/wiki/Dirichlet_distribution" title="Dirichlet distribution">Dirichlet-distributions</a>. The Bayesian approach facilitates a seamless intermixing between expert knowledge in the form of subjective probabilities, and objective observations.</p>
<p>Probabilistic pattern classifiers can be used according to a frequentist or a Bayesian approach.</p>
<h2><span class="mw-headline" id="Uses">Uses</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=6" title="Edit section: Uses">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:202px;"><a href="http://en.wikipedia.org/wiki/File:800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg/200px-800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg" width="200" height="133" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d9/800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg/300px-800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d9/800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg/400px-800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="http://en.wikipedia.org/wiki/File:800px-Cool_Kids_of_Death_Off_Festival_p_146-face_selected.jpg" class="internal" title="Enlarge"><img src="http://bits.wikimedia.org/static-1.23wmf18/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
<a href="http://en.wikipedia.org/wiki/Face_recognition" title="Face recognition" class="mw-redirect">The face was automatically detected</a> by special software.</div>
</div>
</div>
<p>Within medical science, pattern recognition is the basis for <a href="http://en.wikipedia.org/wiki/Computer-aided_diagnosis" title="Computer-aided diagnosis">computer-aided diagnosis</a> (CAD) systems. CAD describes a procedure that supports the doctor's interpretations and findings.</p>
<div class="thumb tright">
<div class="thumbinner" style="width:222px;"><a href="http://en.wikipedia.org/wiki/File:SRT_Shape_Recognition_Technology_Principles.png" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/SRT_Shape_Recognition_Technology_Principles.png/220px-SRT_Shape_Recognition_Technology_Principles.png" width="220" height="124" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/SRT_Shape_Recognition_Technology_Principles.png/330px-SRT_Shape_Recognition_Technology_Principles.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d0/SRT_Shape_Recognition_Technology_Principles.png/440px-SRT_Shape_Recognition_Technology_Principles.png 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="http://en.wikipedia.org/wiki/File:SRT_Shape_Recognition_Technology_Principles.png" class="internal" title="Enlarge"><img src="http://bits.wikimedia.org/static-1.23wmf18/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Pattern &amp; Shape Recognition Technology (SRT) in a <a href="http://en.wikipedia.org/wiki/People_counter" title="People counter">people counter</a> system</div>
</div>
</div>
<p>Other typical applications of pattern recognition techniques are automatic <a href="http://en.wikipedia.org/wiki/Speech_recognition" title="Speech recognition">speech recognition</a>, <a href="http://en.wikipedia.org/wiki/Document_classification" title="Document classification">classification of text into several categories</a> (e.g., spam/non-spam email messages), the <a href="http://en.wikipedia.org/wiki/Handwriting_recognition" title="Handwriting recognition">automatic recognition of handwritten postal codes</a> on postal envelopes, automatic recognition of images of human faces, or handwriting image extraction from medical forms.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5"><span>[</span>5<span>]</span></a></sup> The last two examples form the subtopic <a href="http://en.wikipedia.org/wiki/Image_analysis" title="Image analysis">image analysis</a> of pattern recognition that deals with digital images as input to pattern recognition systems.<sup id="cite_ref-duda2001_6-0" class="reference"><a href="#cite_note-duda2001-6"><span>[</span>6<span>]</span></a></sup><sup id="cite_ref-7" class="reference"><a href="#cite_note-7"><span>[</span>7<span>]</span></a></sup></p>
<p>Optical character recognition is a classic example of the application of a pattern classifier, see <a rel="nofollow" class="external text" href="http://cmp.felk.cvut.cz/cmp/software/stprtool/examples/ocr_system.gif">OCR-example</a>. The method of signing one's name was captured with stylus and overlay starting in 1990.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (January 2011)">citation needed</span></a></i>]</sup> The strokes, speed, relative min, relative max, acceleration and pressure is used to uniquely identify and confirm identity. Banks were first offered this technology, but were content to collect from the FDIC for any bank fraud and did not want to inconvenience customers..<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (January 2011)">citation needed</span></a></i>]</sup></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Artificial_neural_networks" title="Artificial neural networks" class="mw-redirect">Artificial neural networks</a> (neural net classifiers) and <a href="http://en.wikipedia.org/wiki/Deep_Learning" title="Deep Learning" class="mw-redirect">Deep Learning</a> have many real-world applications in image processing, a few examples:</li>
<li>identification and authentication: e.g., license plate recognition,<sup id="cite_ref-8" class="reference"><a href="#cite_note-8"><span>[</span>8<span>]</span></a></sup> fingerprint analysis and face detection/verification;<sup id="cite_ref-9" class="reference"><a href="#cite_note-9"><span>[</span>9<span>]</span></a></sup></li>
<li>medical diagnosis: e.g., screening for cervical cancer (Papnet)<sup id="cite_ref-10" class="reference"><a href="#cite_note-10"><span>[</span>10<span>]</span></a></sup> or breast tumors;</li>
<li>defence: various navigation and guidance systems, target recognition systems, shape recognition technology etc.</li>
</ul>
<p>For a discussion of the aforementioned applications of neural networks in image processing, see e.g.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11"><span>[</span>11<span>]</span></a></sup></p>
<p>In psychology, pattern recognition, making sense of and identifying the objects we see is closely related to perception, which explains how the sensory inputs we receive are made meaningful. Pattern recognition can be thought of in two different ways: the first being template matching and the second being feature detection. A template is a pattern used to produce items of the same proportions. The template-matching hypothesis suggests that incoming stimuli are compared with templates in the long term memory. If there is a match, the stimulus is identified. Feature detection models, such as the Pandemonium system for classifying letters (Selfridge, 1959), suggest that the stimuli are broken down into their component parts for identification. For example, a capital E has three horizontal lines and one vertical line.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12"><span>[</span>12<span>]</span></a></sup></p>
<h2><span class="mw-headline" id="Algorithms">Algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=7" title="Edit section: Algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Algorithms for pattern recognition depend on the type of label output, on whether learning is supervised or unsupervised, and on whether the algorithm is statistical or non-statistical in nature. Statistical algorithms can further be categorized as <a href="http://en.wikipedia.org/wiki/Generative_model" title="Generative model">generative</a> or <a href="http://en.wikipedia.org/wiki/Discriminative_model" title="Discriminative model">discriminative</a>.</p>
<h3><span class="mw-headline" id="Classification_algorithms_.28supervised_algorithms_predicting_categorical_labels.29"><a href="http://en.wikipedia.org/wiki/Classification_(machine_learning)" title="Classification (machine learning)" class="mw-redirect">Classification</a> algorithms (<a href="http://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">supervised</a> algorithms predicting <a href="http://en.wikipedia.org/wiki/Categorical_data" title="Categorical data" class="mw-redirect">categorical</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=8" title="Edit section: Classification algorithms (supervised algorithms predicting categorical labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Parametric:<sup id="cite_ref-13" class="reference"><a href="#cite_note-13"><span>[</span>13<span>]</span></a></sup></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">Linear discriminant analysis</a></li>
<li><a href="http://en.wikipedia.org/wiki/Quadratic_classifier" title="Quadratic classifier">Quadratic discriminant analysis</a></li>
<li><a href="http://en.wikipedia.org/wiki/Maximum_entropy_classifier" title="Maximum entropy classifier" class="mw-redirect">Maximum entropy classifier</a> (aka <a href="http://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, <a href="http://en.wikipedia.org/wiki/Multinomial_logistic_regression" title="Multinomial logistic regression">multinomial logistic regression</a>): Note that logistic regression is an algorithm for classification, despite its name. (The name comes from the fact that logistic regression uses an extension of a linear regression model to model the probability of an input being in a particular class.)</li>
</ul>
<p>Nonparametric:<sup id="cite_ref-14" class="reference"><a href="#cite_note-14"><span>[</span>14<span>]</span></a></sup></p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Decision_tree" title="Decision tree">Decision trees</a>, <a href="http://en.wikipedia.org/wiki/Decision_list" title="Decision list">decision lists</a></li>
<li><a href="http://en.wikipedia.org/wiki/Variable_kernel_density_estimation#Use_for_statistical_classification" title="Variable kernel density estimation">Kernel estimation</a> and <a href="http://en.wikipedia.org/wiki/K-nearest-neighbor" title="K-nearest-neighbor" class="mw-redirect">K-nearest-neighbor</a> algorithms</li>
<li><a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes classifier</a></li>
<li><a href="http://en.wikipedia.org/wiki/Neural_network" title="Neural network" class="mw-redirect">Neural networks</a> (multi-layer perceptrons)</li>
<li><a href="http://en.wikipedia.org/wiki/Perceptron" title="Perceptron">Perceptrons</a></li>
<li><a href="http://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">Support vector machines</a></li>
<li><a href="http://en.wikipedia.org/wiki/Gene_expression_programming" title="Gene expression programming">Gene expression programming</a></li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Clustering_algorithms_.28unsupervised_algorithms_predicting_categorical_labels.29"><a href="http://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a> algorithms (<a href="http://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised</a> algorithms predicting <a href="http://en.wikipedia.org/wiki/Categorical_data" title="Categorical data" class="mw-redirect">categorical</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=9" title="Edit section: Clustering algorithms (unsupervised algorithms predicting categorical labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li>Categorical <a href="http://en.wikipedia.org/wiki/Mixture_model" title="Mixture model">mixture models</a></li>
<li><a href="http://en.wikipedia.org/wiki/Deep_learning" title="Deep learning">Deep learning methods</a></li>
<li><a href="http://en.wikipedia.org/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical clustering</a> (agglomerative or divisive)</li>
<li><a href="http://en.wikipedia.org/wiki/K-means_clustering" title="K-means clustering">K-means clustering</a></li>
<li><a href="http://en.wikipedia.org/wiki/Correlation_clustering" title="Correlation clustering">Correlation clustering</a></li>
<li><a href="http://en.wikipedia.org/wiki/Kernel_principal_component_analysis" title="Kernel principal component analysis">Kernel principal component analysis</a> (Kernel PCA)</li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Ensemble_learning_algorithms_.28supervised_meta-algorithms_for_combining_multiple_learning_algorithms_together.29"><a href="http://en.wikipedia.org/wiki/Ensemble_learning" title="Ensemble learning">Ensemble learning</a> algorithms (supervised <a href="http://en.wikipedia.org/wiki/Meta-algorithm" title="Meta-algorithm" class="mw-redirect">meta-algorithms</a> for combining multiple learning algorithms together)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=10" title="Edit section: Ensemble learning algorithms (supervised meta-algorithms for combining multiple learning algorithms together)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Boosting_(meta-algorithm)" title="Boosting (meta-algorithm)" class="mw-redirect">Boosting (meta-algorithm)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bootstrap aggregating</a> ("bagging")</li>
<li><a href="http://en.wikipedia.org/wiki/Ensemble_averaging" title="Ensemble averaging">Ensemble averaging</a></li>
<li><a href="http://en.wikipedia.org/w/index.php?title=Mixture_of_experts&amp;action=edit&amp;redlink=1" class="new" title="Mixture of experts (page does not exist)">Mixture of experts</a>, <a href="http://en.wikipedia.org/w/index.php?title=Hierarchical_mixture_of_experts&amp;action=edit&amp;redlink=1" class="new" title="Hierarchical mixture of experts (page does not exist)">hierarchical mixture of experts</a></li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="General_algorithms_for_predicting_arbitrarily-structured_.28sets_of.29_labels">General algorithms for predicting arbitrarily-structured (sets of) labels</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=11" title="Edit section: General algorithms for predicting arbitrarily-structured (sets of) labels">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayesian networks</a></li>
<li><a href="http://en.wikipedia.org/wiki/Markov_random_field" title="Markov random field">Markov random fields</a></li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Multilinear_subspace_learning_algorithms_.28predicting_labels_of_multidimensional_data_using_tensor_representations.29"><a href="http://en.wikipedia.org/wiki/Multilinear_subspace_learning" title="Multilinear subspace learning">Multilinear subspace learning</a> algorithms (predicting labels of multidimensional data using <a href="http://en.wikipedia.org/wiki/Tensor" title="Tensor">tensor</a> representations)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=12" title="Edit section: Multilinear subspace learning algorithms (predicting labels of multidimensional data using tensor representations)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Unsupervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Multilinear_principal_component_analysis" title="Multilinear principal component analysis">Multilinear principal component analysis</a> (MPCA)</li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Parsing_algorithms_.28predicting_tree_structured_labels.29"><a href="Parsing.html" title="Parsing">Parsing</a> algorithms (predicting <a href="http://en.wikipedia.org/wiki/Tree_structure" title="Tree structure">tree structured</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=13" title="Edit section: Parsing algorithms (predicting tree structured labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supervised and unsupervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Probabilistic_context_free_grammar" title="Probabilistic context free grammar" class="mw-redirect">Probabilistic context free grammars</a> (PCFGs)</li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Real-valued_sequence_labeling_algorithms_.28predicting_sequences_of_real-valued_labels.29">Real-valued <a href="http://en.wikipedia.org/wiki/Sequence_labeling" title="Sequence labeling">sequence labeling</a> algorithms (predicting sequences of <a href="http://en.wikipedia.org/wiki/Real_number" title="Real number">real-valued</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=14" title="Edit section: Real-valued sequence labeling algorithms (predicting sequences of real-valued labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supervised (?):</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Kalman_filter" title="Kalman filter">Kalman filters</a></li>
<li><a href="http://en.wikipedia.org/wiki/Particle_filter" title="Particle filter">Particle filters</a></li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Regression_algorithms_.28predicting_real-valued_labels.29"><a href="http://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">Regression</a> algorithms (predicting <a href="http://en.wikipedia.org/wiki/Real_number" title="Real number">real-valued</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=15" title="Edit section: Regression algorithms (predicting real-valued labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Gaussian_process_regression" title="Gaussian process regression" class="mw-redirect">Gaussian process regression</a> (kriging)</li>
<li><a href="http://en.wikipedia.org/wiki/Linear_regression" title="Linear regression">Linear regression</a> and extensions</li>
<li><a href="http://en.wikipedia.org/wiki/Neural_network" title="Neural network" class="mw-redirect">Neural networks</a> and <a href="http://en.wikipedia.org/wiki/Deep_learning" title="Deep learning">Deep learning methods</a></li>
</ul>
<p>Unsupervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Independent_component_analysis" title="Independent component analysis">Independent component analysis</a> (ICA)</li>
<li><a href="http://en.wikipedia.org/wiki/Principal_components_analysis" title="Principal components analysis" class="mw-redirect">Principal components analysis</a> (PCA)</li>
</ul>
<p><br /></p>
<h3><span class="mw-headline" id="Sequence_labeling_algorithms_.28predicting_sequences_of_categorical_labels.29"><a href="http://en.wikipedia.org/wiki/Sequence_labeling" title="Sequence labeling">Sequence labeling</a> algorithms (predicting sequences of <a href="http://en.wikipedia.org/wiki/Categorical_data" title="Categorical data" class="mw-redirect">categorical</a> labels)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=16" title="Edit section: Sequence labeling algorithms (predicting sequences of categorical labels)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Conditional_random_field" title="Conditional random field">Conditional random fields</a> (CRFs)</li>
<li><a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov models</a> (HMMs)</li>
<li><a href="http://en.wikipedia.org/wiki/Maximum_entropy_Markov_model" title="Maximum entropy Markov model" class="mw-redirect">Maximum entropy Markov models</a> (MEMMs)</li>
<li><a href="http://en.wikipedia.org/wiki/Recurrent_neural_networks" title="Recurrent neural networks" class="mw-redirect">Recurrent neural networks</a></li>
</ul>
<p>Unsupervised:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov models</a> (HMMs)</li>
</ul>
<h2><span class="mw-headline" id="Which_classifier_to_choose_for_a_classification_task.3F">Which classifier to choose for a classification task?</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=17" title="Edit section: Which classifier to choose for a classification task?">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>This article contains an extensive list of statistical classifiers for <a href="http://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">supervised</a> and <a href="http://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised</a> classification tasks, clustering and general regression prediction. When considering building a classifier e.g., for a software application, a number of different aspects influence the choice of the preferred classifier type to use.</p>
<p>Building or <i>training</i> a classifier is essentially <a href="http://en.wikipedia.org/wiki/Statistical_inference" title="Statistical inference">statistical inference</a>. This means that an attempt is made to identify stochastic (often unknown) relations between feature variables and the categories to be predicted. For example, the influence of increased cholesterol on the risk of a heart attack for a patient, within the next year. Which other variables besides the current cholesterol level determine this risk? The two categories to 'predict' by a classifier are 'heart attack likely', or 'heart attack unlikely'.</p>
<p>The theoretically optimal classifier is called the <b><a href="http://en.wikipedia.org/wiki/Bayes_error_rate" title="Bayes error rate">Bayes classifier</a></b>. It minimizes the loss-function or <i>risk</i> as defined <a href="http://en.wikipedia.org/wiki/Supervised_learning#How_supervised_learning_algorithms_work" title="Supervised learning">here</a>. When all types of misclassifications are associated with equal losses (outcome A becomes B is as undesired as when outcome B becomes A), the Bayes classifier with the minimal error rate (on a test set) is the optimal one for the classification task. In general, it is unknown what is the optimal classifier type and true parameters <img class="tex" alt="\boldsymbol{\theta}" src="http://upload.wikimedia.org/math/2/8/9/28964e5d44aaa561601a17e49bb5a8d9.png" />. However, bounds on the optimal Bayes error rate have been derived. For, for example, the K-nearest neighbor classifier theoretical results are derived that <a href="http://en.wikipedia.org/wiki/K-nearest-neighbor#Properties" title="K-nearest-neighbor" class="mw-redirect">bound the error rate</a>, in relation to the optimal Bayes error rate.</p>
<p>In essence, building a classifier brings model selection with it. <a href="http://en.wikipedia.org/wiki/Feature_selection" title="Feature selection">Feature selection</a> – using only a subset of the available feature variables to predict the most likely categorical outcome – by itself entails model selection. Choosing among the extensive set of different classifiers makes model selection even more complex. A theoretical analysis of this search problem has been presented as the <b><a href="http://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization" title="No free lunch in search and optimization">no free lunch theorem</a>:<sup id="cite_ref-15" class="reference"><a href="#cite_note-15"><span>[</span>15<span>]</span></a></sup></b> No particular classification algorithm is 'the best' for all problems. The pragmatic approach to this open problem is to combine prior knowledge of the classification task (e.g. <a href="http://en.wikipedia.org/wiki/Statistical_distribution" title="Statistical distribution" class="mw-redirect">distributional assumptions</a>) with a search process where different types of classifiers are developed and their performance compared.</p>
<p>The search for the 'best' model that predicts observations and relations between these is a problem that was discovered already in ancient Greece. In medieval times, <a href="http://en.wikipedia.org/wiki/Occam%27s_razor" title="Occam's razor">Occam's razor</a> was formulated:</p>
<p>“plurality should not be posited without necessity”.</p>
<p>In this context, it means that if a simple classifier with only a few parameters (small <img class="tex" alt="\boldsymbol{\theta}" src="http://upload.wikimedia.org/math/2/8/9/28964e5d44aaa561601a17e49bb5a8d9.png" />) does the job as well as a much more complex classification algorithm, choose the simpler one. Only to add that the performance of a classifier is but one of the criteria to apply when choosing the best classification model. <a href="http://en.wikipedia.org/wiki/Statistical_distribution" title="Statistical distribution" class="mw-redirect">Distributional assumptions</a>, insight provided into the discovered relations between variables, whether the classification algorithm can cope with missing feature variables, whether a change in class <a href="http://en.wikipedia.org/wiki/Prior_probability" title="Prior probability">prior probability</a> <sup id="cite_ref-16" class="reference"><a href="#cite_note-16"><span>[</span>16<span>]</span></a></sup> can be incorporated, speed of the training algorithm, memory requirements, parallelization of the classification process, resemblance to the human perceptual system, and other aspects as well. In visual pattern recognition <a href="http://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition#Class-invariance" title="Prior knowledge for pattern recognition">invariance</a> to variations in color, rotation and scale are extra properties that need to be accounted for.</p>
<h3><span class="mw-headline" id="Supervised_classification">Supervised classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=18" title="Edit section: Supervised classification">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>When choosing the most appropriate supervised classifier, the generally accepted heuristic is to:</p>
<ol>
<li>Separate the available data, at random, into a <a href="http://en.wikipedia.org/wiki/Training_set" title="Training set">training set</a> and a <a href="http://en.wikipedia.org/wiki/Test_set" title="Test set">test set</a>. Use the test set only for the final performance comparison of the trained classifiers.</li>
<li>Experiment by training a number of classification algorithms, including <a href="http://en.wikipedia.org/wiki/Parametric_statistics" title="Parametric statistics">parametric</a> (<a href="http://en.wikipedia.org/wiki/Discriminant_analysis" title="Discriminant analysis" class="mw-redirect">discriminant analysis</a>, <a href="http://en.wikipedia.org/wiki/Multinomial_logistic_regression" title="Multinomial logistic regression">multinomial classifier</a><sup id="cite_ref-Glick1973_17-0" class="reference"><a href="#cite_note-Glick1973-17"><span>[</span>17<span>]</span></a></sup> ) and <a href="http://en.wikipedia.org/wiki/Non-parametric_statistics" title="Non-parametric statistics">non-parametric</a> algorithms (<a href="http://en.wikipedia.org/wiki/K-nearest-neighbor" title="K-nearest-neighbor" class="mw-redirect">k-nearest neighbor</a>, a <a href="http://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">support vector machine</a>, a <a href="http://en.wikipedia.org/wiki/Neural_networks" title="Neural networks" class="mw-redirect">feed-forward neural network</a>, a standard <a href="http://en.wikipedia.org/wiki/Decision_tree" title="Decision tree">decision-tree algorithm</a>).</li>
<li>Test distributional assumptions of the (continuous) feature-distributions per category. Are they <a href="http://en.wikipedia.org/wiki/Gaussian_distribution" title="Gaussian distribution" class="mw-redirect">Gaussian</a>?</li>
<li>Which subset of feature variables contributes mostly to the discriminative performance of the classifier?</li>
<li>Are elaborate <a href="http://en.wikipedia.org/wiki/Confidence_interval" title="Confidence interval">confidence intervals</a> needed for the <a href="http://en.wikipedia.org/wiki/Bayes_error_rate" title="Bayes error rate">error-rates</a> and class-predictions?<sup id="cite_ref-mclachlan2004_18-0" class="reference"><a href="#cite_note-mclachlan2004-18"><span>[</span>18<span>]</span></a></sup></li>
<li>White-box versus black-box considerations may render specific classifiers unsuited for the job.</li>
</ol>
<h3><span class="mw-headline" id="Unsupervised_classification">Unsupervised classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=19" title="Edit section: Unsupervised classification">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=20" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="div-col columns column-count column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;">
<ul>
<li><a href="http://en.wikipedia.org/wiki/Adaptive_resonance_theory" title="Adaptive resonance theory">Adaptive resonance theory</a></li>
<li><a href="http://en.wikipedia.org/wiki/Artificial_neural_networks" title="Artificial neural networks" class="mw-redirect">Artificial neural networks</a></li>
<li><a href="http://en.wikipedia.org/wiki/Cache_language_model" title="Cache language model">Cache language model</a></li>
<li><a href="http://en.wikipedia.org/wiki/Compound_term_processing" title="Compound term processing">Compound term processing</a></li>
<li><a href="http://en.wikipedia.org/wiki/Computer-aided_diagnosis" title="Computer-aided diagnosis">Computer-aided diagnosis</a></li>
<li><a href="Data_mining.html" title="Data mining">Data mining</a></li>
<li><a href="http://en.wikipedia.org/wiki/Deep_Learning" title="Deep Learning" class="mw-redirect">Deep Learning</a></li>
<li><a href="http://en.wikipedia.org/wiki/List_of_numerical_analysis_software" title="List of numerical analysis software">List of numerical analysis software</a></li>
<li><a href="http://en.wikipedia.org/wiki/List_of_numerical_libraries" title="List of numerical libraries">List of numerical libraries</a></li>
<li><a href="Machine_learning.html" title="Machine learning">Machine learning</a></li>
<li><a href="http://en.wikipedia.org/wiki/Multilinear_subspace_learning" title="Multilinear subspace learning">Multilinear subspace learning</a></li>
<li><a href="http://en.wikipedia.org/wiki/Neocognitron" title="Neocognitron">Neocognitron</a></li>
<li><a href="http://en.wikipedia.org/wiki/Pattern_language" title="Pattern language">Pattern language</a></li>
<li><a href="http://en.wikipedia.org/wiki/Pattern_recognition_(psychology)" title="Pattern recognition (psychology)">Pattern recognition (psychology)</a></li>
<li><a href="http://en.wikipedia.org/wiki/Perception" title="Perception">Perception</a></li>
<li><a href="http://en.wikipedia.org/wiki/Perceptual_learning" title="Perceptual learning">Perceptual learning</a></li>
<li><a href="http://en.wikipedia.org/wiki/Predictive_analytics" title="Predictive analytics">Predictive analytics</a></li>
<li><a href="http://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition" title="Prior knowledge for pattern recognition">Prior knowledge for pattern recognition</a></li>
<li><a href="http://en.wikipedia.org/wiki/Sequence_mining" title="Sequence mining" class="mw-redirect">Sequence mining</a></li>
<li><a href="http://en.wikipedia.org/wiki/Template_matching" title="Template matching">Template matching</a></li>
<li><a href="http://en.wikipedia.org/wiki/Thin-slicing" title="Thin-slicing">Thin-slicing</a></li>
<li><a href="http://en.wikipedia.org/wiki/Contextual_image_classification" title="Contextual image classification">Contextual image classification</a></li>
</ul>
</div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=21" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><span class="citation foldoc">This article is based on material taken from the <a href="http://en.wikipedia.org/wiki/Free_On-line_Dictionary_of_Computing" title="Free On-line Dictionary of Computing">Free On-line Dictionary of Computing</a> prior to 1 November 2008 and incorporated under the "relicensing" terms of the <a href="http://en.wikipedia.org/wiki/GNU_Free_Documentation_License" title="GNU Free Documentation License">GFDL</a>, version 1.3 or later.</span></p>
<div class="reflist" style="list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Isabelle Guyon Clopinet, André Elisseeff (2003). <i>An Introduction to Variable and Feature Selection</i>. The Journal of Machine Learning Research, Vol. 3, 1157-1182. <a rel="nofollow" class="external text" href="http://www-vis.lbl.gov/~romano/mlgroup/papers/guyon03a.pdf">Link</a></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><span class="citation journal">Iman Foroutan, Jack Sklansky (1987). "Feature Selection for Automatic Classification of Non-Gaussian Data". <i>IEEE Transactions on Systems, Man and Cybernetics</i> <b>17</b> (2): 187–198. <a href="Digital_object_identifier.html" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1109%2FTSMC.1987.4309029">10.1109/TSMC.1987.4309029</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.atitle=Feature+Selection+for+Automatic+Classification+of+Non-Gaussian+Data&amp;rft.au=Iman+Foroutan%2C+Jack+Sklansky&amp;rft.aulast=Iman+Foroutan%2C+Jack+Sklansky&amp;rft.date=1987&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1109%2FTSMC.1987.4309029&amp;rft.issue=2&amp;rft.jtitle=IEEE+Transactions+on+Systems%2C+Man+and+Cybernetics&amp;rft.pages=187%26ndash%3B198&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=17" class="Z3988"><span style="display:none;">&#160;</span></span>.</span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><span class="citation journal">Mineichi Kudo, Jack Sklansky (2000). "Comparison of algorithms that select features for pattern classifiers". <i>Pattern Recognition</i> <b>33</b> (1): 25–41. <a href="Digital_object_identifier.html" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1016%2FS0031-3203(99)00041-2">10.1016/S0031-3203(99)00041-2</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.atitle=Comparison+of+algorithms+that+select+features+for+pattern+classifiers&amp;rft.aulast=Mineichi+Kudo%2C+Jack+Sklansky&amp;rft.au=Mineichi+Kudo%2C+Jack+Sklansky&amp;rft.date=2000&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1016%2FS0031-3203%2899%2900041-2&amp;rft.issue=1&amp;rft.jtitle=Pattern+Recognition&amp;rft.pages=25%26ndash%3B41&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=33" class="Z3988"><span style="display:none;">&#160;</span></span>.</span></li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">For <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a> the parameter vector <img class="tex" alt="\boldsymbol\theta" src="http://upload.wikimedia.org/math/f/3/7/f371c7df934e1fa0f81fb845eb819600.png" /> consists of the two mean vectors <img class="tex" alt="\boldsymbol\mu_1" src="http://upload.wikimedia.org/math/7/b/6/7b6ee696fde80406d51b13caf0e892b8.png" /> and <img class="tex" alt="\boldsymbol\mu_2" src="http://upload.wikimedia.org/math/6/3/6/636f6a59288d40e5bba55b470856fe3c.png" /> and the common <a href="http://en.wikipedia.org/wiki/Covariance_matrix" title="Covariance matrix">covariance matrix</a> <img class="tex" alt="\boldsymbol\Sigma" src="http://upload.wikimedia.org/math/8/0/1/80108c5d571bee97b8ef476b86216da6.png" />.</span></li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><span class="citation journal">Milewski, Robert; Govindaraju, Venu (31 March 2008). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=1324656">"Binarization and cleanup of handwritten text from carbon copy medical form images"</a>. <i>Pattern Recognition</i> <b>41</b> (4): 1308–1315. <a href="Digital_object_identifier.html" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1016%2Fj.patcog.2007.08.018">10.1016/j.patcog.2007.08.018</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.atitle=Binarization+and+cleanup+of+handwritten+text+from+carbon+copy+medical+form+images&amp;rft.aufirst=Robert&amp;rft.aulast=Milewski&amp;rft.au=Milewski%2C+Robert&amp;rft.date=31+March+2008&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1324656&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patcog.2007.08.018&amp;rft.issue=4&amp;rft.jtitle=Pattern+Recognition&amp;rft.pages=1308%E2%80%931315&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=41" class="Z3988"><span style="display:none;">&#160;</span></span> <span style="display:none;font-size:100%" class="error citation-comment">Cite uses deprecated parameters (<a href="http://en.wikipedia.org/wiki/Help:CS1_errors#deprecated_params" title="Help:CS1 errors">help</a>)</span></span></li>
<li id="cite_note-duda2001-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-duda2001_6-0">^</a></b></span> <span class="reference-text">Richard O. Duda, <a href="http://en.wikipedia.org/wiki/Peter_E._Hart" title="Peter E. Hart">Peter E. Hart</a>, David G. Stork (2001) <i>Pattern classification</i> (2nd edition), Wiley, New York, <a href="http://en.wikipedia.org/wiki/Special:BookSources/0471056693" class="internal mw-magiclink-isbn">ISBN 0-471-05669-3</a></span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">R. Brunelli, <i>Template Matching Techniques in Computer Vision: Theory and Practice</i>, Wiley, <a href="http://en.wikipedia.org/wiki/Special:BookSources/9780470517062" class="internal mw-magiclink-isbn">ISBN 978-0-470-51706-2</a>, 2009</span></li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://anpr-tutorial.com/">THE AUTOMATIC NUMBER PLATE RECOGNITION TUTORIAL</a> <a rel="nofollow" class="external free" href="http://anpr-tutorial.com/">http://anpr-tutorial.com/</a></span></li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.cs.cmu.edu/afs/cs.cmu.edu/usr/mitchell/ftp/faces.html">Neural Networks for Face Recognition</a> Companion to Chapter 4 of the textbook Machine Learning.</span></li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://health-asia.org/papnet-for-cervical-screening/">PAPNET For Cervical Screening</a> <a rel="nofollow" class="external free" href="http://health-asia.org/papnet-for-cervical-screening/">http://health-asia.org/papnet-for-cervical-screening/</a></span></li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><span class="citation journal">Egmont-Petersen, M., de Ridder, D., Handels, H. (2002). "Image processing with neural networks - a review". <i>Pattern Recognition</i> <b>35</b> (10): 2279–2301. <a href="Digital_object_identifier.html" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1016%2FS0031-3203(01)00178-9">10.1016/S0031-3203(01)00178-9</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.atitle=Image+processing+with+neural+networks+-+a+review&amp;rft.au=Egmont-Petersen%2C+M.%2C+de+Ridder%2C+D.%2C+Handels%2C+H.&amp;rft.aulast=Egmont-Petersen%2C+M.%2C+de+Ridder%2C+D.%2C+Handels%2C+H.&amp;rft.date=2002&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1016%2FS0031-3203%2801%2900178-9&amp;rft.issue=10&amp;rft.jtitle=Pattern+Recognition&amp;rft.pages=2279%26ndash%3B2301&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=35" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://www.s-cool.co.uk/a-level/psychology/attention/revise-it/pattern-recognition">"A-level Psychology Attention Revision - Pattern recognition | S-cool, the revision website"</a>. S-cool.co.uk<span class="reference-accessdate">. Retrieved 2012-09-17</span>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.btitle=A-level+Psychology+Attention+Revision+-+Pattern+recognition+%26%23124%3B+S-cool%2C+the+revision+website&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww.s-cool.co.uk%2Fa-level%2Fpsychology%2Fattention%2Frevise-it%2Fpattern-recognition&amp;rft.pub=S-cool.co.uk&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text">Assuming known distributional shape of feature distributions per class, such as the <a href="http://en.wikipedia.org/wiki/Gaussian_distribution" title="Gaussian distribution" class="mw-redirect">Gaussian</a> shape.</span></li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text">No distributional assumption regarding shape of feature distributions per class.</span></li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text">David H. Wolpert (2001). <i>The Supervised Learning No Free Lunch Theorems</i>. Technical report MS-269-1, NASA Ames Research Center. <a rel="nofollow" class="external text" href="http://www.no-free-lunch.org/Wolp01a.pdf">Link</a></span></li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text">Relative frequency of each class in the training and test sets.</span></li>
<li id="cite_note-Glick1973-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-Glick1973_17-0">^</a></b></span> <span class="reference-text">Ned Glick (1973) <i>Sample-Based Multinomial Classification</i>, <i>Biometrics</i>, Vol. 29, No. 2, pp. 241-256.</span></li>
<li id="cite_note-mclachlan2004-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-mclachlan2004_18-0">^</a></b></span> <span class="reference-text">Geoffrey J. McLachlan (2004) <i>Discriminant Analysis and Statistical Pattern Recognition</i>, Wiley Series in Probability and Statistics, New Jersey, <a href="http://en.wikipedia.org/wiki/Special:BookSources/0471691151" class="internal mw-magiclink-isbn">ISBN 0-471-69115-1</a></span></li>
</ol>
</div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=22" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><span class="citation book">Fukunaga, Keinosuke (1990). <i>Introduction to Statistical Pattern Recognition</i> (2nd ed.). Boston: Academic Press. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/0-12-269851-7" title="Special:BookSources/0-12-269851-7">0-12-269851-7</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.aufirst=Keinosuke&amp;rft.au=Fukunaga%2C+Keinosuke&amp;rft.aulast=Fukunaga&amp;rft.btitle=Introduction+to+Statistical+Pattern+Recognition&amp;rft.date=1990&amp;rft.edition=2nd&amp;rft.genre=book&amp;rft.isbn=0-12-269851-7&amp;rft.place=Boston&amp;rft.pub=Academic+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book"><a href="http://en.wikipedia.org/wiki/Christopher_Bishop" title="Christopher Bishop">Bishop, Christopher</a> (2006). <i>Pattern Recognition and Machine Learning</i>. Berlin: Springer. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/0-387-31073-8" title="Special:BookSources/0-387-31073-8">0-387-31073-8</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.au=Bishop%2C+Christopher&amp;rft.aufirst=Christopher&amp;rft.aulast=Bishop&amp;rft.btitle=Pattern+Recognition+and+Machine+Learning&amp;rft.date=2006&amp;rft.genre=book&amp;rft.isbn=0-387-31073-8&amp;rft.place=Berlin&amp;rft.pub=Springer&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book">Koutroumbas, Konstantinos; Theodoridis, Sergios (2008). <i>Pattern Recognition</i> (4th ed.). Boston: Academic Press. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/1-59749-272-8" title="Special:BookSources/1-59749-272-8">1-59749-272-8</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.aufirst=Konstantinos&amp;rft.au=Koutroumbas%2C+Konstantinos&amp;rft.aulast=Koutroumbas&amp;rft.au=Theodoridis%2C+Sergios&amp;rft.btitle=Pattern+Recognition&amp;rft.date=2008&amp;rft.edition=4th&amp;rft.genre=book&amp;rft.isbn=1-59749-272-8&amp;rft.place=Boston&amp;rft.pub=Academic+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book">Hornegger, Joachim; Paulus, Dietrich W. R. (1999). <i>Applied Pattern Recognition: A Practical Introduction to Image and Speech Processing in C++</i> (2nd ed.). San Francisco: Morgan Kaufmann Publishers. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/3-528-15558-2" title="Special:BookSources/3-528-15558-2">3-528-15558-2</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.aufirst=Joachim&amp;rft.au=Hornegger%2C+Joachim&amp;rft.aulast=Hornegger&amp;rft.au=Paulus%2C+Dietrich+W.+R.&amp;rft.btitle=Applied+Pattern+Recognition%3A+A+Practical+Introduction+to+Image+and+Speech+Processing+in+C%2B%2B&amp;rft.date=1999&amp;rft.edition=2nd&amp;rft.genre=book&amp;rft.isbn=3-528-15558-2&amp;rft.place=San+Francisco&amp;rft.pub=Morgan+Kaufmann+Publishers&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book">Schuermann, Juergen (1996). <i>Pattern Classification: A Unified View of Statistical and Neural Approaches</i>. New York: Wiley. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/0-471-13534-8" title="Special:BookSources/0-471-13534-8">0-471-13534-8</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.aufirst=Juergen&amp;rft.aulast=Schuermann&amp;rft.au=Schuermann%2C+Juergen&amp;rft.btitle=Pattern+Classification%3A+A+Unified+View+of+Statistical+and+Neural+Approaches&amp;rft.date=1996&amp;rft.genre=book&amp;rft.isbn=0-471-13534-8&amp;rft.place=New+York&amp;rft.pub=Wiley&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book">Godfried T. Toussaint, ed. (1988). <i>Computational Morphology</i>. Amsterdam: North-Holland Publishing Company.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.btitle=Computational+Morphology&amp;rft.date=1988&amp;rft.genre=book&amp;rft.place=Amsterdam&amp;rft.pub=North-Holland+Publishing+Company&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation book">Kulikowski, Casimir A.; Weiss, Sholom M. (1991). <i>Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems</i>. Machine Learning. San Francisco: Morgan Kaufmann Publishers. <a href="International_Standard_Book_Number.html" title="International Standard Book Number">ISBN</a>&#160;<a href="http://en.wikipedia.org/wiki/Special:BookSources/1-55860-065-5" title="Special:BookSources/1-55860-065-5">1-55860-065-5</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.aufirst=Casimir+A.&amp;rft.au=Kulikowski%2C+Casimir+A.&amp;rft.aulast=Kulikowski&amp;rft.au=Weiss%2C+Sholom+M.&amp;rft.btitle=Computer+Systems+That+Learn%3A+Classification+and+Prediction+Methods+from+Statistics%2C+Neural+Nets%2C+Machine+Learning%2C+and+Expert+Systems&amp;rft.date=1991&amp;rft.genre=book&amp;rft.isbn=1-55860-065-5&amp;rft.place=San+Francisco&amp;rft.pub=Morgan+Kaufmann+Publishers&amp;rft.series=Machine+Learning&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><span class="citation journal">Jain, Anil.K.; Duin, Robert.P.W.; Mao, Jianchang (2000). "Statistical pattern recognition: a review". <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> <b>22</b> (1): 4–37. <a href="Digital_object_identifier.html" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1109%2F34.824819">10.1109/34.824819</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APattern+recognition&amp;rft.atitle=Statistical+pattern+recognition%3A+a+review&amp;rft.au=Duin%2C+Robert.P.W.&amp;rft.aufirst=Anil.K.&amp;rft.au=Jain%2C+Anil.K.&amp;rft.aulast=Jain&amp;rft.au=Mao%2C+Jianchang&amp;rft.date=2000&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1109%2F34.824819&amp;rft.issue=1&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.pages=4%26ndash%3B37&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=22" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li><a rel="nofollow" class="external text" href="http://www.egmont-petersen.nl/classifiers.htm">An introductory tutorial to classifiers (introducing the basic terms, with numeric example)</a></li>
</ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit&amp;section=23" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.iapr.org/">The International Association for Pattern Recognition</a></li>
<li><a rel="nofollow" class="external text" href="http://cgm.cs.mcgill.ca/~godfried/teaching/pr-web.html">List of Pattern Recognition web sites</a></li>
<li><a rel="nofollow" class="external text" href="http://www.jprr.org/">Journal of Pattern Recognition Research</a></li>
<li><a rel="nofollow" class="external text" href="http://www.docentes.unal.edu.co/morozcoa/docs/pr.php">Pattern Recognition Info</a></li>
<li><a rel="nofollow" class="external text" href="http://www.sciencedirect.com/science/journal/00313203">Pattern Recognition</a> (Journal of the Pattern Recognition Society)</li>
<li><a rel="nofollow" class="external text" href="http://www.worldscinet.com/ijprai/mkt/archive.shtml">International Journal of Pattern Recognition and Artificial Intelligence</a></li>
<li><a rel="nofollow" class="external text" href="http://www.inderscience.com/ijapr">International Journal of Applied Pattern Recognition</a></li>
<li><a rel="nofollow" class="external text" href="http://www.openpr.org.cn/">Open Pattern Recognition Project</a>, intended to be an open source platform for sharing algorithms of pattern recognition</li>
<li><a rel="nofollow" class="external text" href="http://www.intelnics.com/opennn">OpenNN: Open Neural Networks Library</a></li>
</ul>


<!-- 
NewPP limit report
Parsed by mw1009
CPU time usage: 0.924 seconds
Real time usage: 1.307 seconds
Preprocessor visited node count: 1586/1000000
Preprocessor generated node count: 6578/1500000
Post‐expand include size: 26310/2048000 bytes
Template argument size: 1195/2048000 bytes
Highest expansion depth: 11/40
Expensive parser function count: 1/500
Lua time usage: 0.107/10.000 seconds
Lua memory usage: 2.36 MB/50 MB
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:126706-0!*!0!!en!4!*!math=0 and timestamp 20140326204615
 -->
<noscript><img src="http://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>								<div class="printfooter">
				Retrieved from "<a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;oldid=600603195">http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;oldid=600603195</a>"				</div>
												<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="http://en.wikipedia.org/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="http://en.wikipedia.org/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li><li><a href="http://en.wikipedia.org/wiki/Category:Formal_sciences" title="Category:Formal sciences">Formal sciences</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="http://en.wikipedia.org/wiki/Category:Pages_containing_cite_templates_with_deprecated_parameters" title="Category:Pages containing cite templates with deprecated parameters">Pages containing cite templates with deprecated parameters</a></li><li><a href="http://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="http://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_January_2011" title="Category:Articles with unsourced statements from January 2011">Articles with unsourced statements from January 2011</a></li></ul></div></div>												<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
				<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul>
<li id="pt-createaccount"><a href="http://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Pattern+recognition&amp;type=signup">Create account</a></li><li id="pt-login"><a href="http://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Pattern+recognition" title="You're encouraged to log in; however, it's not mandatory. [o]" accesskey="o">Log in</a></li>	</ul>
</div>
				<div id="left-navigation">
					<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul>
					<li  id="ca-nstab-main" class="selected"><span><a href="Pattern_recognition.html"  title="View the content page [c]" accesskey="c">Article</a></span></li>
					<li  id="ca-talk"><span><a href="http://en.wikipedia.org/wiki/Talk:Pattern_recognition"  title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>
			</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<h3 id="mw-vector-current-variant">
		</h3>
	<h3 id="p-variants-label"><span>Variants</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>
				</div>
				<div id="right-navigation">
					<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul>
					<li id="ca-view" class="selected"><span><a href="Pattern_recognition.html" >Read</a></span></li>
					<li id="ca-edit"><span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=edit"  title="You can edit this page. &#10;Please review your changes before saving. [e]" accesskey="e">Edit</a></span></li>
					<li id="ca-history" class="collapsible"><span><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=history"  title="Past versions of this page [h]" accesskey="h">View history</a></span></li>
			</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<h3 id="p-cactions-label"><span>Actions</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>
<div id="p-search" role="search">
	<h3><label for="searchInput">Search</label></h3>
	<form action="http://en.wikipedia.org/w/index.php" id="searchform">
					<div id="simpleSearch">
					<input type="search" name="search" placeholder="Search" title="Search Wikipedia [f]" accesskey="f" id="searchInput" /><input type="hidden" value="Special:Search" name="title" /><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton" /><input type="submit" name="go" value="Go" title="Go to a page with this exact name if one exists" id="searchButton" class="searchButton" />		</div>
	</form>
</div>
				</div>
			</div>
			<div id="mw-panel">
					<div id="p-logo" role="banner"><a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="Main_Page.html"  title="Visit the main page"></a></div>
				<div class="portal" role="navigation" id='p-navigation' aria-labelledby='p-navigation-label'>
	<h3 id='p-navigation-label'>Navigation</h3>
	<div class="body">
		<ul>
			<li id="n-mainpage-description"><a href="Main_Page.html" title="Visit the main page [z]" accesskey="z">Main page</a></li>
			<li id="n-contents"><a href="http://en.wikipedia.org/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
			<li id="n-featuredcontent"><a href="http://en.wikipedia.org/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li>
			<li id="n-currentevents"><a href="http://en.wikipedia.org/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
			<li id="n-randompage"><a href="http://en.wikipedia.org/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			<li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li>
			<li id="n-shoplink"><a href="http://shop.wikimedia.org/" title="Visit the Wikimedia Shop">Wikimedia Shop</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-interaction' aria-labelledby='p-interaction-label'>
	<h3 id='p-interaction-label'>Interaction</h3>
	<div class="body">
		<ul>
			<li id="n-help"><a href="http://en.wikipedia.org/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			<li id="n-aboutsite"><a href="http://en.wikipedia.org/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
			<li id="n-portal"><a href="http://en.wikipedia.org/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
			<li id="n-recentchanges"><a href="http://en.wikipedia.org/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
			<li id="n-contactpage"><a href="http://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact page</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-tb' aria-labelledby='p-tb-label'>
	<h3 id='p-tb-label'>Tools</h3>
	<div class="body">
		<ul>
			<li id="t-whatlinkshere"><a href="http://en.wikipedia.org/wiki/Special:WhatLinksHere/Pattern_recognition" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
			<li id="t-recentchangeslinked"><a href="http://en.wikipedia.org/wiki/Special:RecentChangesLinked/Pattern_recognition" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
			<li id="t-upload"><a href="http://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li>
			<li id="t-specialpages"><a href="http://en.wikipedia.org/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li>
			<li id="t-permalink"><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;oldid=600603195" title="Permanent link to this revision of the page">Permanent link</a></li>
			<li id="t-info"><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;action=info">Page information</a></li>
			<li id="t-wikibase"><a href="http://www.wikidata.org/wiki/Q378859" title="Link to connected data repository item [g]" accesskey="g">Data item</a></li>
<li id="t-cite"><a href="http://en.wikipedia.org/w/index.php?title=Special:Cite&amp;page=Pattern_recognition&amp;id=600603195" title="Information on how to cite this page">Cite this page</a></li>		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-coll-print_export' aria-labelledby='p-coll-print_export-label'>
	<h3 id='p-coll-print_export-label'>Print/export</h3>
	<div class="body">
		<ul>
			<li id="coll-create_a_book"><a href="http://en.wikipedia.org/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Pattern+recognition">Create a book</a></li>
			<li id="coll-download-as-rl"><a href="http://en.wikipedia.org/w/index.php?title=Special:Book&amp;bookcmd=render_article&amp;arttitle=Pattern+recognition&amp;oldid=600603195&amp;writer=rl">Download as PDF</a></li>
			<li id="t-print"><a href="http://en.wikipedia.org/w/index.php?title=Pattern_recognition&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-lang' aria-labelledby='p-lang-label'>
	<h3 id='p-lang-label'>Languages</h3>
	<div class="body">
		<ul>
			<li class="interlanguage-link interwiki-ar"><a href="http://ar.wikipedia.org/wiki/تمييز_الأنماط" title="تمييز الأنماط – Arabic" lang="ar" hreflang="ar">العربية</a></li>
			<li class="interlanguage-link interwiki-ca"><a href="http://ca.wikipedia.org/wiki/Reconeixement_de_patrons" title="Reconeixement de patrons – Catalan" lang="ca" hreflang="ca">Català</a></li>
			<li class="interlanguage-link interwiki-de"><a href="http://de.wikipedia.org/wiki/Mustererkennung" title="Mustererkennung – German" lang="de" hreflang="de">Deutsch</a></li>
			<li class="interlanguage-link interwiki-el"><a href="http://el.wikipedia.org/wiki/Αναγνώριση_προτύπων" title="Αναγνώριση προτύπων – Greek" lang="el" hreflang="el">Ελληνικά</a></li>
			<li class="interlanguage-link interwiki-es"><a href="http://es.wikipedia.org/wiki/Reconocimiento_de_patrones" title="Reconocimiento de patrones – Spanish" lang="es" hreflang="es">Español</a></li>
			<li class="interlanguage-link interwiki-fa"><a href="http://fa.wikipedia.org/wiki/بازشناخت_الگو" title="بازشناخت الگو – Persian" lang="fa" hreflang="fa">فارسی</a></li>
			<li class="interlanguage-link interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Reconnaissance_de_formes" title="Reconnaissance de formes – French" lang="fr" hreflang="fr">Français</a></li>
			<li class="interlanguage-link interwiki-ko"><a href="http://ko.wikipedia.org/wiki/패턴_인식" title="패턴 인식 – Korean" lang="ko" hreflang="ko">한국어</a></li>
			<li class="interlanguage-link interwiki-id"><a href="http://id.wikipedia.org/wiki/Pengenalan_pola" title="Pengenalan pola – Indonesian" lang="id" hreflang="id">Bahasa Indonesia</a></li>
			<li class="interlanguage-link interwiki-it"><a href="http://it.wikipedia.org/wiki/Riconoscimento_di_pattern" title="Riconoscimento di pattern – Italian" lang="it" hreflang="it">Italiano</a></li>
			<li class="interlanguage-link interwiki-jv"><a href="http://jv.wikipedia.org/wiki/Pangenalan_pola" title="Pangenalan pola – Javanese" lang="jv" hreflang="jv">Basa Jawa</a></li>
			<li class="interlanguage-link interwiki-kk"><a href="http://kk.wikipedia.org/wiki/Бейнені_айырып_тану" title="Бейнені айырып тану – Kazakh" lang="kk" hreflang="kk">Қазақша</a></li>
			<li class="interlanguage-link interwiki-lt"><a href="http://lt.wikipedia.org/wiki/Atpažinimo_teorija" title="Atpažinimo teorija – Lithuanian" lang="lt" hreflang="lt">Lietuvių</a></li>
			<li class="interlanguage-link interwiki-ms"><a href="http://ms.wikipedia.org/wiki/Pengecaman_pola" title="Pengecaman pola – Malay" lang="ms" hreflang="ms">Bahasa Melayu</a></li>
			<li class="interlanguage-link interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Patroonherkenning" title="Patroonherkenning – Dutch" lang="nl" hreflang="nl">Nederlands</a></li>
			<li class="interlanguage-link interwiki-ja"><a href="http://ja.wikipedia.org/wiki/パターン認識" title="パターン認識 – Japanese" lang="ja" hreflang="ja">日本語</a></li>
			<li class="interlanguage-link interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Rozpoznawanie_wzorców" title="Rozpoznawanie wzorców – Polish" lang="pl" hreflang="pl">Polski</a></li>
			<li class="interlanguage-link interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Reconhecimento_de_padrões" title="Reconhecimento de padrões – Portuguese" lang="pt" hreflang="pt">Português</a></li>
			<li class="interlanguage-link interwiki-ru"><a href="http://ru.wikipedia.org/wiki/Теория_распознавания_образов" title="Теория распознавания образов – Russian" lang="ru" hreflang="ru">Русский</a></li>
			<li class="interlanguage-link interwiki-sr"><a href="http://sr.wikipedia.org/wiki/Prepoznavanje_obrazaca" title="Prepoznavanje obrazaca – Serbian" lang="sr" hreflang="sr">Српски / srpski</a></li>
			<li class="interlanguage-link interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Hahmontunnistus" title="Hahmontunnistus – Finnish" lang="fi" hreflang="fi">Suomi</a></li>
			<li class="interlanguage-link interwiki-tl"><a href="http://tl.wikipedia.org/wiki/Pagkilala_ng_paterno" title="Pagkilala ng paterno – Tagalog" lang="tl" hreflang="tl">Tagalog</a></li>
			<li class="interlanguage-link interwiki-th"><a href="http://th.wikipedia.org/wiki/การรู้จำแบบ" title="การรู้จำแบบ – Thai" lang="th" hreflang="th">ไทย</a></li>
			<li class="interlanguage-link interwiki-tr"><a href="http://tr.wikipedia.org/wiki/Örüntü_tanıma" title="Örüntü tanıma – Turkish" lang="tr" hreflang="tr">Türkçe</a></li>
			<li class="interlanguage-link interwiki-uk"><a href="http://uk.wikipedia.org/wiki/Теорія_розпізнавання_образів" title="Теорія розпізнавання образів – Ukrainian" lang="uk" hreflang="uk">Українська</a></li>
			<li class="interlanguage-link interwiki-vi"><a href="http://vi.wikipedia.org/wiki/Nhận_dạng_mẫu" title="Nhận dạng mẫu – Vietnamese" lang="vi" hreflang="vi">Tiếng Việt</a></li>
			<li class="interlanguage-link interwiki-zh"><a href="http://zh.wikipedia.org/wiki/模式识别" title="模式识别 – Chinese" lang="zh" hreflang="zh">中文</a></li>
			<li class="uls-p-lang-dummy"><a href="#"></a></li>
			<li class="wbc-editpage"><a href="http://www.wikidata.org/wiki/Q378859#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></li>
		</ul>
	</div>
</div>
			</div>
		</div>
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last modified on 21 March 2014 at 15:03.<br /></li>
											<li id="footer-info-copyright">Text is available under the <a rel="license" href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="http://wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="http://wikimediafoundation.org/wiki/Privacy_policy">Privacy Policy.</a> <br/>
Wikipedia® is a registered trademark of the <a href="http://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="http://en.wikipedia.org/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
											<li id="footer-places-disclaimer"><a href="http://en.wikipedia.org/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
											<li id="footer-places-contact"><a href="http://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
											<li id="footer-places-developers"><a class="external" href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
											<li id="footer-places-mobileview"><a href="http://en.m.wikipedia.org/wiki/Pattern_recognition" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
					<li id="footer-copyrightico">
						<a href="http://wikimediafoundation.org/"><img src="http://bits.wikimedia.org/images/wikimedia-button.png" width="88" height="31" alt="Wikimedia Foundation"/></a>
					</li>
					<li id="footer-poweredbyico">
						<a href="http://www.mediawiki.org/"><img src="http://bits.wikimedia.org/static-1.23wmf18/skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" width="88" height="31" /></a>
					</li>
				</ul>
						<div style="clear:both"></div>
		</div>
		<script>/*<![CDATA[*/window.jQuery && jQuery.ready();/*]]>*/</script><script>if(window.mw){
mw.loader.state({"site":"loading","user":"ready","user.groups":"ready"});
}</script>
<script>if(window.mw){
mw.loader.load(["ext.cite","mobile.desktop","mediawiki.action.view.postEdit","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.DRN-wizard","ext.gadget.charinsert","mw.MwEmbedSupport.style","ext.wikimediaShopLink.core","ext.navigationTiming","schema.UniversalLanguageSelector","ext.uls.eventlogger","ext.uls.interlanguage","skins.vector.collapsibleNav"],null,true);
}</script>
<script src="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=scripts&amp;skin=vector&amp;*"></script>
<!-- Served by mw1168 in 0.208 secs. -->
	</body>

<!-- Mirrored from en.wikipedia.org/wiki/Pattern_recognition by HTTrack Website Copier/3.x [XR&CO'2013], Sat, 29 Mar 2014 23:55:29 GMT -->
</html>
